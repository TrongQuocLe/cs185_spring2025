{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc175c8-f744-4655-9037-b313c486c951",
   "metadata": {},
   "source": [
    "# Creating the Initial Conditions\n",
    "\n",
    "This notebook serves as a demo for the creation of the initial conditions. These initial conditions are shown for Mike's Calfornia Current regional model. You can follow and/or adapt this notebook based on your configuration.\n",
    "\n",
    "First, import packages to re-create and visualize the model fields here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "836f57c0-6983-48ce-b8a0-31c5b04463a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea649be-1868-47e6-a895-1cf4b03d5cdf",
   "metadata": {},
   "source": [
    "Next, define the location of the input directory for the model. This is the same directory that holds the bathymetry file generated in the previous notebooks for this model example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d8f138-1542-4af2-845e-ab0acad86dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input directory\n",
    "input_dir = '/Users/spartan/Downloads/cs185c_spring2025/project/input'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea43d2c-8106-4b7e-9d71-dda71ff556e4",
   "metadata": {},
   "source": [
    "## Constructing the Initial Conditions\n",
    "For my model, I will use a model state from the ECCO Version 5 state estimate. I will prepare the initial condition fields in 7 steps:\n",
    "1. download 5 fields and 4 grid files generated by the ECCO model in 2008\n",
    "2. read the ECCO model grid\n",
    "3. read in the bathymetry for my model as well as its grid\n",
    "4. prepare the ECCO fields for interpolation\n",
    "5. interpolate the ECCO fields onto my model grid and store each as a binary file\n",
    "6. plot the interpolated fields to ensure they look as expected\n",
    "7. prepare notes on the run-time options I will use to implement my initial condition approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5328af-a028-439b-a89a-4f39b72a9a65",
   "metadata": {},
   "source": [
    "### Step 1: Download the ECCO fields\n",
    "To begin, I downloaded the model fields generated by the ECCO Version 5 Alpha state estimate. These fields are available [HERE](https://ecco.jpl.nasa.gov/drive/files/Version5/Alpha/nctiles_monthly). In particular, I downloaded the following list of files that contain the field pertaining to starting point of my model (January 2008):\n",
    "\n",
    "| Variable | File Name |\n",
    "| -------- | --------- |\n",
    "|THETA|THETA/THETA_2008.nc|\n",
    "|SALT|SALT/SALT_2008.nc|\n",
    "|UVEL|UVELMASS/UVELMASS_2008.nc|\n",
    "|VVEL|VVELMASS/VVELMASS_2008.nc|\n",
    "|ETAN|ETHAN/ETAN_2008.nc|\n",
    "\n",
    "I stored these fields in the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d9856c-ec0b-4f6e-9f9c-c18a73cd6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/spartan/Downloads/cs185c_spring2025/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170a9e7-8862-4e25-b732-1268f2c77c5a",
   "metadata": {},
   "source": [
    "### Step 2: Read in the ECCO grid\n",
    "To read in the ECCO fields, I will rely on the `grid` module from the `eccoseas.ecco` package [HERE](https://github.com/mhwood/eccoseas), which I import here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d18072-c8a6-425f-a5f6-75dc2ffc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.ecco import grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a925b6ec-93ab-429b-a830-d6591b15a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_XC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='XC')\n",
    "ecco_YC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='YC')\n",
    "ecco_hFacC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacC')\n",
    "ecco_hFacW_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacW')\n",
    "ecco_hFacS_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacS')\n",
    "ecco_RF_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf96ac-d0e5-4e53-884f-16e0fec32152",
   "metadata": {},
   "source": [
    "As described [HERE](https://ecco-v4-python-tutorial.readthedocs.io/ECCO_v4_Plotting_Tiles.html), the ECCO grid has 13 tiles but only 1 or 2 may pertain to my local area. To determine which tiles correspond to my region, I'll read in my model grid next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a135ac-a5bb-4766-83b5-60039dcc0c56",
   "metadata": {},
   "source": [
    "### Step 3: Read in the Model Grid and Generate a Mask\n",
    "Here, I will recreate the grid I will use in my model and read in the bathymetry file (see previous notebooks for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f48b8cc3-eb40-40c3-b61e-1359d986109d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 86400 into shape (480,2160)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m XC, YC \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(xc, yc)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# read in the bathymetry file\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m bathy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCA_bathymetry.bin\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>f4\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(np\u001b[38;5;241m.\u001b[39mshape(XC))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 86400 into shape (480,2160)"
     ]
    }
   ],
   "source": [
    "# define the parameters that will be used in the data file\n",
    "delX = 1/12\n",
    "delY = 1/16\n",
    "xgOrigin = -90\n",
    "ygOrigin = 60\n",
    "n_rows = 480 # 30 * 16\n",
    "n_cols = 2160 # 180 * 12\n",
    "\n",
    "# recreate the grids that will be used in the model\n",
    "xc = np.arange(xgOrigin+delX/2, xgOrigin+n_cols*delX, delX)\n",
    "yc = np.arange(ygOrigin+delY/2, ygOrigin+n_rows*delY+delY/2, delY)\n",
    "XC, YC = np.meshgrid(xc, yc)\n",
    "\n",
    "# read in the bathymetry file \n",
    "#TODO: Change CA_bathymetry.bin to south artic\n",
    "bathy = np.fromfile(os.path.join(input_dir,'Artic_bathymetry.bin'),'>f4').reshape(np.shape(XC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8e15a-b056-4c97-86b1-c3eb4c5e020c",
   "metadata": {},
   "source": [
    "With an eye toward the interpolation to come next, I will make a mask to determine where the interpolatation will take place. I will create this mask by recreating the `hFac` field for my model using the `hFac` module from the `eccoseas` package: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "088d4f4e-52b9-4ec4-b416-d033a4f94633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.downscale import hFac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9cf36-029c-431c-b2f0-5fe80a139c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = bathy\n",
    "delR = np.array([ 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.01,\n",
    "                 10.03, 10.11, 10.32, 10.80, 11.76, 13.42, 16.04, 19.82, 24.85,\n",
    "                 31.10, 38.42, 46.50, 55.00, 63.50, 71.58, 78.90, 85.15, 90.18,\n",
    "                 93.96, 96.58, 98.25, 99.25,100.01,101.33,104.56,111.33,122.83,\n",
    "                 139.09,158.94,180.83,203.55,226.50,249.50,272.50,295.50,318.50,\n",
    "                 341.50,364.50,387.50,410.50,433.50,456.50,])\n",
    "hFacC = hFac.create_hFacC_grid(depth, delR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb82b3d-ffa2-4312-916f-3325a0089c6b",
   "metadata": {},
   "source": [
    "The mask is generated by setting all of the non-zero `hFac` points to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcfe0a-3641-43d7-99aa-88a48310eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.copy(hFacC)\n",
    "mask[mask>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601f994-42b7-4840-8da4-73f98c9269f4",
   "metadata": {},
   "source": [
    "To double check the mask was created as expected, I will plot it in comparison to the bathymetry here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea1cb2-e29e-49c8-befe-eba9e857244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "C = plt.pcolormesh(XC, YC, bathy, vmin=-5000, vmax=0, cmap='Blues_r')\n",
    "plt.colorbar(C, orientation = 'horizontal')\n",
    "plt.title('Model Bathymetry')\n",
    "\n",
    "depth_level = 0\n",
    "plt.subplot(1,2,2)\n",
    "C = plt.pcolormesh(XC, YC, mask[35], vmin=0, vmax=1, cmap='Greys')\n",
    "plt.colorbar(C, orientation = 'horizontal')\n",
    "plt.title('Mask (depth level = '+str(depth_level))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5abdd9-4043-4967-9651-556a2d083e6c",
   "metadata": {},
   "source": [
    "Seems reasonable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e0e64-13eb-4122-ae3c-0fead095fc9b",
   "metadata": {},
   "source": [
    "### Step 4: Prepare the grids for interpolation\n",
    "At this point, we can use the geometry of both grids to check to see which tiles have the information we need. After some trial and error (and referencing the ECCO page), I find that tiles 8 and 11 have the points I need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dfc32-ab58-422e-9b5a-47985af1e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ECCO tile points from tiles 8 and 11\n",
    "plt.plot(ecco_XC_tiles[11],ecco_YC_tiles[11],'k.')\n",
    "plt.plot(ecco_XC_tiles[8],ecco_YC_tiles[8],'k.')\n",
    "\n",
    "# plot the boundary of the CA model\n",
    "plt.plot(XC[:,0],YC[:,0], 'g-')\n",
    "plt.plot(XC[:,-1],YC[:,-1], 'g-')\n",
    "plt.plot(XC[0,:],YC[0,:], 'g-')\n",
    "plt.plot(XC[-1,:],YC[-1,:], 'g-')\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332346e-acea-4d60-9494-8d850824b8f4",
   "metadata": {},
   "source": [
    "As we can see, my model boundary (green) is completely surrounded by the points in tile 8 and 11 (black). I also note that there is extraneous information in points with longitude greater than ~140 - I will omit these points as well. Given these observations, now I read in points from just those tiles to use in interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5f5ec-1a41-4da6-81aa-9d121dfa023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_list = [8,11]\n",
    "\n",
    "# determine the number of points in each set\n",
    "total_points = 0\n",
    "for tile_number in tile_list:\n",
    "    total_points += np.size(ecco_XC_tiles[tile_number])\n",
    "\n",
    "# make empty arrays to fill in\n",
    "ecco_XC_points = np.zeros((total_points, ))\n",
    "ecco_YC_points = np.zeros((total_points, ))\n",
    "ecco_hFacC_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacW_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacS_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_mask_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "\n",
    "# loop through the tiles and fill in the XC, YC, and mask points for interpolation\n",
    "points_counted = 0\n",
    "for tile_number in tile_list:\n",
    "    tile_N = np.size(ecco_XC_tiles[tile_number])\n",
    "    \n",
    "    ecco_XC_points[points_counted:points_counted+tile_N] = ecco_XC_tiles[tile_number].ravel()\n",
    "    ecco_YC_points[points_counted:points_counted+tile_N] = ecco_YC_tiles[tile_number].ravel()\n",
    "    \n",
    "    for k in range(np.size(ecco_RF_tiles[tile_number])):\n",
    "        level_hFacC = ecco_hFacC_tiles[tile_number][k, :, :]\n",
    "        level_hFacW = ecco_hFacW_tiles[tile_number][k, :, :]\n",
    "        level_hFacS = ecco_hFacS_tiles[tile_number][k, :, :]\n",
    "        level_mask = np.copy(level_hFacC)\n",
    "        level_mask[level_mask>0] = 1\n",
    "        ecco_hFacC_points[k, points_counted:points_counted+tile_N] = level_hFacC.ravel()\n",
    "        ecco_hFacW_points[k, points_counted:points_counted+tile_N] = level_hFacW.ravel()\n",
    "        ecco_hFacS_points[k, points_counted:points_counted+tile_N] = level_hFacS.ravel()\n",
    "        ecco_mask_points[k,points_counted:points_counted+tile_N] = level_mask.ravel()\n",
    "    \n",
    "    points_counted += tile_N\n",
    "\n",
    "# remove the points with positive longitude\n",
    "local_indices = ecco_XC_points<0\n",
    "ecco_mask_points = ecco_mask_points[:, local_indices]\n",
    "ecco_hFacC_points = ecco_hFacC_points[:, local_indices]\n",
    "ecco_hFacW_points = ecco_hFacW_points[:, local_indices]\n",
    "ecco_hFacS_points = ecco_hFacS_points[:, local_indices]\n",
    "ecco_YC_points = ecco_YC_points[local_indices]\n",
    "ecco_XC_points = ecco_XC_points[local_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462677-8079-45e5-9faf-d39452350218",
   "metadata": {},
   "source": [
    "Next, we'll read in the real data fields and apply the modifications. First, create a dictionary to store the file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb96e5-bef6-4307-a5b3-f4441a930f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file dictionary to loop over\n",
    "\n",
    "# test dictionary\n",
    "file_prefix_dict = {'ETAN':'ETAN_2008.nc'}\n",
    "file_prefix_dict = {'THETA':'THETA_2008.nc'}\n",
    "\n",
    "# once tested with the above dict, run and comment with this one\n",
    "# file_prefix_dict = {'ETAN':'ETAN_2008.nc',\n",
    "#                     'THETA':'THETA_2008.nc',\n",
    "#                     'SALT':'SALT_2008.nc',\n",
    "#                     'UVEL':'UVELMASS_2008.nc',\n",
    "#                     'VVEL':'VVELMASS_2008.nc'}\n",
    "variable_names = list(file_prefix_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5206c-6f45-431e-9988-a1b007ce954e",
   "metadata": {},
   "source": [
    "Now, read the initial condition fields from the same tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963b363-9245-4f9b-9f40-2b7318286460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list to hold all of the ECCO grids\n",
    "init_grids = []\n",
    "\n",
    "# loop through each variable to read in the grid\n",
    "for variable_name in variable_names:\n",
    "    \n",
    "    if variable_name == 'ETAN':\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,file_prefix_dict[variable_name]))\n",
    "        grid = ds.variables[variable_name][:,:,:,:]\n",
    "        ds.close()\n",
    "    elif 'VEL' in variable_name:\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,'UVELMASS_2008.nc'))\n",
    "        u_grid = ds.variables['UVELMASS'][:,:,:,:,:]\n",
    "        ds.close()\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,'VVELMASS_2008.nc'))\n",
    "        v_grid = ds.variables['VVELMASS'][:,:,:,:,:]\n",
    "        ds.close()\n",
    "    else:\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,file_prefix_dict[variable_name]))\n",
    "        grid = ds.variables[variable_name][:,:,:,:,:]\n",
    "        ds.close()\n",
    "    \n",
    "    # create a grid of zeros to fill in\n",
    "    N = np.shape(grid)[-1]*np.shape(grid)[-2]\n",
    "    if variable_name == 'ETAN':\n",
    "        init_grid = np.zeros((1, N*len(tile_list)))\n",
    "    else:\n",
    "        init_grid = np.zeros((np.size(ecco_RF_tiles[1]), N*len(tile_list)))\n",
    "\n",
    "    # loop through the tiles\n",
    "    points_counted = 0\n",
    "    for tile_number in tile_list:\n",
    "        if variable_name == 'ETAN':\n",
    "            init_grid[0,points_counted:points_counted+N] = \\\n",
    "                 grid[0, tile_number-1, :, :].ravel()\n",
    "        elif 'VEL' in variable_name: # when using velocity, need to consider the tile rotations\n",
    "            if variable_name == 'UVEL':\n",
    "                if tile_number<7:\n",
    "                    for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                        init_grid[k,points_counted:points_counted+N] = \\\n",
    "                             u_grid[0, k, tile_number-1, :, :].ravel()\n",
    "                else:\n",
    "                    for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                        init_grid[k,points_counted:points_counted+N] = \\\n",
    "                             v_grid[0, k, tile_number-1, :, :].ravel()\n",
    "            if variable_name == 'VVEL':\n",
    "                if tile_number<7:\n",
    "                    for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                        init_grid[k,points_counted:points_counted+N] = \\\n",
    "                             v_grid[0, k, tile_number-1, :, :].ravel()\n",
    "                else:\n",
    "                    for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                        init_grid[k,points_counted:points_counted+N] = \\\n",
    "                             -1*u_grid[0, k, tile_number-1, :, :].ravel()\n",
    "        else:\n",
    "            for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                init_grid[k,points_counted:points_counted+N] = \\\n",
    "                     grid[0, k, tile_number-1, :, :].ravel()\n",
    "        points_counted += N\n",
    "\n",
    "    # remove the points with positive longitudes\n",
    "    init_grid = init_grid[:,local_indices]\n",
    "\n",
    "    # apply some corrections\n",
    "    if variable_name == 'UVEL':\n",
    "        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "            non_zero_indices = ecco_hFacW_points[k,:]!=0\n",
    "            init_grid[k,non_zero_indices] = init_grid[k,non_zero_indices]/(ecco_hFacW_points[k,non_zero_indices])\n",
    "    if variable_name == 'VVEL':\n",
    "        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "            non_zero_indices = ecco_hFacS_points[k,:]!=0\n",
    "            init_grid[k,non_zero_indices] = init_grid[k,non_zero_indices]/(ecco_hFacS_points[k,non_zero_indices])\n",
    "    \n",
    "    init_grids.append(init_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e32043-a3a3-49df-a724-de2be9f98708",
   "metadata": {},
   "source": [
    "### Step 5: Interpolate the Fields onto the Model Grid\n",
    "Next, I will interpolate the ECCO external fields I read in onto my model domain. I will use the `horizonal` module from the `eccoseas` package to accomplish this interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15f228-d61d-4a42-9714-ed5037711b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.downscale import horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aae164-a3f8-470b-a973-7f7ddffdcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each variable and corresponding ECCO grid\n",
    "for variable_name, init_grid in zip(variable_names, init_grids):\n",
    "\n",
    "    # print a message to keep track of which variable we are working on\n",
    "    # uncomment to use\n",
    "    # print('    - Interpolating the '+variable_name+' grid')\n",
    "\n",
    "    if variable_name == 'ETAN':\n",
    "        model_mask = mask[:1,:,:]\n",
    "    else:\n",
    "        model_mask = mask\n",
    "\n",
    "    interpolated_grid = horizontal.downscale_3D_points(np.column_stack([ecco_XC_points, ecco_YC_points]),\n",
    "                                                       init_grid, ecco_mask_points, \n",
    "                                                       XC, YC, model_mask)\n",
    "\n",
    "\n",
    "    # output the interpolated grid\n",
    "    output_file = os.path.join(input_dir,variable_name+'_IC.bin')\n",
    "    interpolated_grid.ravel('C').astype('>f4').tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe30ee2-7b83-498d-813c-9b9ea152ed6f",
   "metadata": {},
   "source": [
    "### Step 6: Plotting the Initial Condition Fields\n",
    "Now that the fields have been generated, I will plot them to ensure they look as expected. First, I'll generate some metadata for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac447d-91d1-4a85-b4c3-12529580db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {'ETAN':[0.1, 0.5, 'viridis', 'm'],\n",
    "            'THETA':[6, 18, 'turbo', 'm'],\n",
    "            'SALT':[32, 35, 'viridis', 'm'],\n",
    "            'UVEL':[-0.5, 0.5, 'seismic', 'm'],\n",
    "            'VVEL':[-0.5, 0.5, 'seismic', 'm']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60e704-57ae-4d35-aca8-2dbc8ad5f84a",
   "metadata": {},
   "source": [
    "Then, I'll create all of the subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd252056-d8e7-4cce-a50d-43e20b50c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "\n",
    "for i in range(len(variable_names)):\n",
    "    variable_name = variable_names[i]\n",
    "    \n",
    "    CA_init_grid = np.fromfile(os.path.join(input_dir,variable_name+'_IC.bin'),'>f4')\n",
    "\n",
    "    if variable_name == 'ETAN':\n",
    "        CA_init_grid = CA_init_grid.reshape((np.shape(XC)[0], np.shape(XC)[1]))\n",
    "    else:\n",
    "        CA_init_grid = CA_init_grid.reshape((np.shape(delR)[0],np.shape(XC)[0], np.shape(XC)[1]))\n",
    "        CA_init_grid = CA_init_grid[10, :, :] # choose just the surface for plotting\n",
    "    \n",
    "    plt.subplot(2,3,i+1)\n",
    "    C = plt.pcolormesh(XC, YC, CA_init_grid,\n",
    "                       vmin=meta_dict[variable_names[i]][0],\n",
    "                       vmax=meta_dict[variable_names[i]][1],\n",
    "                       cmap=meta_dict[variable_names[i]][2])\n",
    "    plt.colorbar(C, label=variable_names[i]+' ('+meta_dict[variable_names[i]][3]+')',fraction=0.26)\n",
    "\n",
    "    if i<5:\n",
    "        plt.gca().set_xticklabels([])\n",
    "    else:\n",
    "        plt.gca().set_xlabel('Longitude')\n",
    "    if i%2==1:\n",
    "        plt.gca().set_yticklabels([])\n",
    "    if i==7:\n",
    "        plt.gca().axis('off')\n",
    "    if i==2:\n",
    "        plt.gca().set_ylabel('Latitude')\n",
    "    plt.title(variable_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ea7f2-2254-47f8-989b-04990088b89a",
   "metadata": {},
   "source": [
    "Looks good! Now we need to make our external forcing and boundary conditions before we're ready to run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeeedb0-d365-4e6a-a6e1-222351fa222f",
   "metadata": {},
   "source": [
    "### Step 7: Run-time considerations\n",
    "To use the grids as initial conditions in the model, I will specify them as \"hydrography\" conditions. Specifically, I will add the following lines to `PARM05` of the data file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea85bef-c9c3-4a89-9094-171b2bea0ce2",
   "metadata": {},
   "source": [
    "```\n",
    "hydrogThetaFile = 'THETA_IC.bin',\n",
    "hydrogSaltFile = 'SALT_IC.bin',\n",
    "uVelInitFile = 'UVEL_IC.bin',\n",
    "vVelInitFile = 'VVEL_IC.bin',\n",
    "pSurfInitFile = 'ETAN_IC.bin',\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs185c",
   "language": "python",
   "name": "cs185c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
